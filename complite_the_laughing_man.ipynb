{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3612jvsc74a57bd05a49a43dbdc81075b29e5ecd09eb50057293e35818ee42103cfdfdfc359e5918",
   "display_name": "Python 3.6.12 64-bit ('tensorflow2_x': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[x,y] = 523,216 [w,h] = 293,293\n",
      "[x,y] = 520,214 [w,h] = 298,298\n",
      "[x,y] = 519,215 [w,h] = 297,297\n",
      "[x,y] = 523,218 [w,h] = 293,293\n",
      "[x,y] = 513,212 [w,h] = 305,305\n",
      "[x,y] = 510,219 [w,h] = 285,285\n",
      "[x,y] = 493,221 [w,h] = 287,287\n",
      "[x,y] = 463,216 [w,h] = 295,295\n",
      "[x,y] = 432,223 [w,h] = 296,296\n",
      "[x,y] = 404,227 [w,h] = 285,285\n",
      "[x,y] = 382,233 [w,h] = 270,270\n",
      "[x,y] = 351,222 [w,h] = 301,301\n",
      "[x,y] = 332,225 [w,h] = 298,298\n",
      "[x,y] = 336,229 [w,h] = 289,289\n",
      "[x,y] = 338,220 [w,h] = 303,303\n",
      "[x,y] = 383,219 [w,h] = 302,302\n",
      "[x,y] = 421,218 [w,h] = 292,292\n",
      "[x,y] = 474,219 [w,h] = 286,286\n",
      "[x,y] = 497,224 [w,h] = 287,287\n",
      "[x,y] = 524,215 [w,h] = 302,302\n",
      "[x,y] = 561,224 [w,h] = 296,296\n",
      "[x,y] = 567,228 [w,h] = 303,303\n",
      "[x,y] = 569,222 [w,h] = 313,313\n",
      "[x,y] = 555,217 [w,h] = 313,313\n",
      "[x,y] = 543,231 [w,h] = 277,277\n",
      "[x,y] = 502,223 [w,h] = 285,285\n",
      "[x,y] = 497,234 [w,h] = 256,256\n",
      "[x,y] = 472,215 [w,h] = 302,302\n",
      "[x,y] = 520,244 [w,h] = 217,217\n",
      "[x,y] = 506,234 [w,h] = 263,263\n",
      "[x,y] = 515,228 [w,h] = 286,286\n",
      "[x,y] = 533,233 [w,h] = 294,294\n",
      "[x,y] = 532,227 [w,h] = 308,308\n",
      "[x,y] = 542,229 [w,h] = 294,294\n",
      "[x,y] = 539,224 [w,h] = 307,307\n",
      "[x,y] = 545,228 [w,h] = 304,304\n",
      "[x,y] = 532,218 [w,h] = 335,335\n",
      "[x,y] = 556,230 [w,h] = 308,308\n",
      "[x,y] = 553,220 [w,h] = 321,321\n",
      "[x,y] = 571,231 [w,h] = 297,297\n",
      "[x,y] = 571,234 [w,h] = 300,300\n",
      "[x,y] = 548,216 [w,h] = 322,322\n",
      "[x,y] = 549,211 [w,h] = 322,322\n",
      "[x,y] = 534,212 [w,h] = 335,335\n",
      "[x,y] = 534,215 [w,h] = 330,330\n",
      "[x,y] = 542,223 [w,h] = 299,299\n",
      "[x,y] = 534,209 [w,h] = 312,312\n",
      "[x,y] = 516,205 [w,h] = 329,329\n",
      "[x,y] = 522,219 [w,h] = 314,314\n",
      "[x,y] = 516,208 [w,h] = 327,327\n",
      "[x,y] = 523,222 [w,h] = 310,310\n",
      "[x,y] = 499,204 [w,h] = 340,340\n",
      "[x,y] = 497,206 [w,h] = 320,320\n",
      "[x,y] = 491,213 [w,h] = 316,316\n",
      "[x,y] = 477,201 [w,h] = 331,331\n",
      "[x,y] = 473,211 [w,h] = 326,326\n",
      "[x,y] = 476,214 [w,h] = 318,318\n",
      "[x,y] = 482,211 [w,h] = 314,314\n",
      "[x,y] = 482,202 [w,h] = 319,319\n",
      "[x,y] = 466,188 [w,h] = 346,346\n",
      "[x,y] = 460,180 [w,h] = 358,358\n",
      "[x,y] = 447,170 [w,h] = 383,383\n",
      "[x,y] = 435,171 [w,h] = 390,390\n",
      "[x,y] = 428,159 [w,h] = 402,402\n",
      "[x,y] = 421,151 [w,h] = 416,416\n",
      "[x,y] = 417,162 [w,h] = 410,410\n",
      "[x,y] = 417,163 [w,h] = 411,411\n",
      "[x,y] = 403,145 [w,h] = 426,426\n",
      "[x,y] = 411,161 [w,h] = 419,419\n",
      "[x,y] = 418,160 [w,h] = 410,410\n",
      "[x,y] = 409,146 [w,h] = 438,438\n",
      "[x,y] = 409,146 [w,h] = 431,431\n",
      "[x,y] = 429,160 [w,h] = 396,396\n",
      "[x,y] = 424,150 [w,h] = 398,398\n",
      "[x,y] = 446,154 [w,h] = 372,372\n",
      "[x,y] = 445,156 [w,h] = 374,374\n",
      "[x,y] = 455,159 [w,h] = 362,362\n",
      "[x,y] = 477,176 [w,h] = 336,336\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "cascade_file = r\"haarcascade_frontalface_alt.xml\"\n",
    "cascade = cv2.CascadeClassifier(cascade_file)\n",
    "mask_img = cv2.imread(\"the_laughing_man.png\", cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "ret = cap.set(3, 1280)\n",
    "ret = cap.set(4, 720)\n",
    "\n",
    "scale_factor = 0.3\n",
    "size = (1280,720)\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "fps = fps * scale_factor\n",
    "fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "out = cv2.VideoWriter('output.mp4', fourcc, fps, size)\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    #顔検出\n",
    "    image_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    front_face_list = cascade.detectMultiScale(image_gray, minSize = (30, 30))\n",
    "\n",
    "    #画像下処理\n",
    "    mask_image_height, mask_image_width = mask_img.shape[:2]\n",
    "\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    pil_frame = Image.fromarray(frame)\n",
    "    pil_frame = pil_frame.convert('RGBA')\n",
    "\n",
    "    #合成\n",
    "\n",
    "    # Display the resulting frame\n",
    "    if len(front_face_list):\n",
    "        for (x,y,w,h) in front_face_list:\n",
    "            print(\"[x,y] = %d,%d [w,h] = %d,%d\" %(x, y, w, h))\n",
    "            \n",
    "\n",
    "            # 置き換える画像のサイズを決める\n",
    "            # # 長い方の幅に合わせる\n",
    "            length = w\n",
    "            if length < h:length = h\n",
    "        \n",
    "            # ちょっと大きめにして位置調整\n",
    "            length = int(length * 1.5)\n",
    "            x = x - int((length - w) / 2)\n",
    "            y = y - int((length - h) / 2)\n",
    "            #画像の大きさを変更、アルゴリズムを選ぶことが可能\n",
    "            mask_tmp = cv2.resize(mask_img, dsize=(length, length), interpolation=cv2.INTER_LINEAR)\n",
    "            mask_tmp = cv2.cvtColor(mask_tmp, cv2.COLOR_BGR2RGBA)\n",
    "            pil_mask_tmp = Image.fromarray(mask_tmp)\n",
    "            pil_mask_tmp = pil_mask_tmp.convert('RGBA')\n",
    "\n",
    "            pil_tmp = Image.new('RGBA', pil_frame.size, (255, 255, 255, 0))\n",
    "            pil_tmp.paste(pil_mask_tmp, (x, y), pil_mask_tmp)\n",
    "            result_image = Image.alpha_composite(pil_frame, pil_tmp)\n",
    "\n",
    "            #ここでRGBA→BGR＋opencvに戻す\n",
    "            result_image = cv2.cvtColor(np.asarray(result_image), cv2.COLOR_RGB2BGR)\n",
    "        cv2.imshow('image', result_image)\n",
    "    # else:\n",
    "        # result_image = cv2.cvtColor(np.asarray(pil_frame), cv2.COLOR_RGB2BGRA)\n",
    "        # cv2.imshow('image', result_image)\n",
    "        # print('not detected')\n",
    "    out.write(result_image)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        # When everything done, release the capture\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ]
}