{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3612jvsc74a57bd05a49a43dbdc81075b29e5ecd09eb50057293e35818ee42103cfdfdfc359e5918",
   "display_name": "Python 3.6.12 64-bit ('tensorflow2_x': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[x,y] = 552,389 [w,h] = 43,43\n",
      "[x,y] = 494,393 [w,h] = 313,313\n",
      "[x,y] = 464,326 [w,h] = 363,363\n",
      "[x,y] = 460,287 [w,h] = 394,394\n",
      "[x,y] = 484,240 [w,h] = 417,417\n",
      "[x,y] = 482,208 [w,h] = 444,444\n",
      "[x,y] = 482,154 [w,h] = 466,466\n",
      "[x,y] = 485,138 [w,h] = 491,491\n",
      "[x,y] = 529,93 [w,h] = 499,499\n",
      "[x,y] = 589,40 [w,h] = 500,500\n",
      "[x,y] = 603,57 [w,h] = 524,524\n",
      "[x,y] = 569,180 [w,h] = 473,473\n",
      "[x,y] = 575,250 [w,h] = 400,400\n",
      "[x,y] = 574,281 [w,h] = 360,360\n",
      "[x,y] = 555,291 [w,h] = 373,373\n",
      "[x,y] = 553,312 [w,h] = 349,349\n",
      "[x,y] = 583,321 [w,h] = 336,336\n",
      "[x,y] = 621,328 [w,h] = 333,333\n",
      "[x,y] = 662,334 [w,h] = 325,325\n",
      "[x,y] = 673,330 [w,h] = 338,338\n",
      "[x,y] = 678,334 [w,h] = 336,336\n",
      "[x,y] = 665,322 [w,h] = 347,347\n",
      "[x,y] = 657,305 [w,h] = 354,354\n",
      "[x,y] = 644,281 [w,h] = 381,381\n",
      "[x,y] = 654,272 [w,h] = 381,381\n",
      "[x,y] = 674,282 [w,h] = 376,376\n",
      "[x,y] = 613,306 [w,h] = 376,376\n",
      "[x,y] = 586,315 [w,h] = 372,372\n",
      "[x,y] = 581,314 [w,h] = 358,358\n",
      "[x,y] = 578,319 [w,h] = 348,348\n",
      "[x,y] = 578,322 [w,h] = 346,346\n",
      "[x,y] = 572,313 [w,h] = 355,355\n",
      "[x,y] = 575,313 [w,h] = 364,364\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "cascade_file = r\"C:\\Users\\tench\\Anaconda projects\\haarcascades/haarcascade_frontalface_alt.xml\"\n",
    "cascade = cv2.CascadeClassifier(cascade_file)\n",
    "mask_img = cv2.imread(\"the_laughing_man.png\", cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "ret = cap.set(3, 1280)\n",
    "ret = cap.set(4, 720)\n",
    "\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    #顔検出\n",
    "    image_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    front_face_list = cascade.detectMultiScale(image_gray, minSize = (30, 30))\n",
    "\n",
    "    #画像下処理\n",
    "    mask_image_height, mask_image_width = mask_img.shape[:2]\n",
    "\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    pil_frame = Image.fromarray(frame)\n",
    "    pil_frame = pil_frame.convert('RGBA')\n",
    "\n",
    "    #合成\n",
    "\n",
    "    # Display the resulting frame\n",
    "    if len(front_face_list):\n",
    "        for (x,y,w,h) in front_face_list:\n",
    "            print(\"[x,y] = %d,%d [w,h] = %d,%d\" %(x, y, w, h))\n",
    "            \n",
    "\n",
    "            # 置き換える画像のサイズを決める\n",
    "            # # 長い方の幅に合わせる\n",
    "            length = w\n",
    "            if length < h:length = h\n",
    "        \n",
    "            # ちょっと大きめにして位置調整\n",
    "            length = int(length * 1.5)\n",
    "            x = x - int((length - w) / 2)\n",
    "            y = y - int((length - h) / 2)\n",
    "            #画像の大きさを変更、アルゴリズムを選ぶことが可能\n",
    "            mask_tmp = cv2.resize(mask_img, dsize=(length, length), interpolation=cv2.INTER_LINEAR)\n",
    "            mask_tmp = cv2.cvtColor(mask_tmp, cv2.COLOR_BGR2RGBA)\n",
    "            pil_mask_tmp = Image.fromarray(mask_tmp)\n",
    "            pil_mask_tmp = pil_mask_tmp.convert('RGBA')\n",
    "\n",
    "            pil_tmp = Image.new('RGBA', pil_frame.size, (255, 255, 255, 0))\n",
    "            pil_tmp.paste(pil_mask_tmp, (x, y), pil_mask_tmp)\n",
    "            result_image = Image.alpha_composite(pil_frame, pil_tmp)\n",
    "\n",
    "            result_image = cv2.cvtColor(np.asarray(result_image), cv2.COLOR_RGB2BGRA)\n",
    "\n",
    "\n",
    "        cv2.imshow('image', result_image)\n",
    "    # else:\n",
    "        # result_image = cv2.cvtColor(np.asarray(pil_frame), cv2.COLOR_RGB2BGRA)\n",
    "        # cv2.imshow('image', result_image)\n",
    "        # print('not detected')\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        # When everything done, release the capture\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ]
}